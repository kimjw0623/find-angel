"""
íŒ¨í„´ ìƒì„± ì „ìš© í´ë˜ìŠ¤ - DBì— íŒ¨í„´ ë°ì´í„° ì €ì¥ë§Œ ë‹´ë‹¹
"""
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import sys
import numpy as np
from scipy.optimize import nnls
import os
from contextlib import contextmanager

from src.database.raw_database import (
    RawDatabaseManager, AuctionAccessory, AuctionBracelet, 
    AuctionStatus, 
    BraceletCombatStat, BraceletBaseStat
)
from src.database.pattern_database import (
    PatternDatabaseManager, AuctionPricePattern, 
    AccessoryPricePattern, BraceletPricePattern
)
from src.common.config import config
from src.common.utils import (
    normalize_base_stat_value, calculate_reasonable_price, extract_common_option_features,
    create_accessory_pattern_key, create_bracelet_pattern_key
)

@contextmanager
def redirect_stdout(file_path, mode='a'):
    """stdoutì„ íŒŒì¼ë¡œ ì„ì‹œ ë¦¬ë‹¤ì´ë ‰íŠ¸í•˜ëŠ” ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    original_stdout = sys.stdout
    with open(file_path, mode, encoding='utf-8') as f:
        sys.stdout = f
        try:
            yield
        finally:
            sys.stdout = original_stdout


def cleanup_old_logs(log_dir='pattern_log', days=3):
    """daysì¼ ì´ìƒ ì§€ë‚œ ë¡œê·¸ íŒŒì¼ ì‚­ì œ"""
    if not os.path.exists(log_dir):
        os.makedirs(log_dir)
        return
        
    cutoff = datetime.now() - timedelta(days=days)
    
    for filename in os.listdir(log_dir):
        filepath = os.path.join(log_dir, filename)
        if os.path.getmtime(filepath) < cutoff.timestamp():
            os.remove(filepath)

class PatternGenerator:
    """íŒ¨í„´ ìƒì„± ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self, main_db_manager: RawDatabaseManager, debug: bool = False):
        self.main_db = main_db_manager  # ê¸°ì¡´ DB (ë°ì´í„° ì½ê¸°ìš©)
        self.pattern_db = PatternDatabaseManager()  # íŒ¨í„´ ë°ì´í„°ë² ì´ìŠ¤
        self.debug = debug
        self.is_generating = False  # íŒ¨í„´ ìƒì„± ì¤‘ í”Œë˜ê·¸
        
        # 15ë¶„ ê°„ê²© ìŠ¤ì¼€ì¤„ë§ì„ ìœ„í•œ ë³€ìˆ˜ë“¤
        self.collection_signal_received = False  # ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì‹ í˜¸ í”Œë˜ê·¸
        self.last_collection_time = None         # ë§ˆì§€ë§‰ ë°ì´í„° ìˆ˜ì§‘ ì‹œê°„
       
        # Configì—ì„œ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        self.EXCLUSIVE_OPTIONS = config.exclusive_options

    def update_pattern(self, pattern_datetime: Optional[datetime] = None, send_signal: bool = True) -> bool:
        """
        í˜„ì¬ ì‹œê° ê¸°ì¤€ìœ¼ë¡œ ì‹œì¥ ê°€ê²© ë°ì´í„°ë¡œ ìºì‹œ ì—…ë°ì´íŠ¸
        
        Args:
            pattern_datetime: íŒ¨í„´ ìƒì„± ê¸°ì¤€ ì‹œê° (Noneì´ë©´ í˜„ì¬ ì‹œê° ì‚¬ìš©)
            send_signal: IPC ì‹ í˜¸ ë°œì†¡ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            bool: ìºì‹œ ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        # ì¤‘ë³µ ì‹¤í–‰ ë°©ì§€
        if self.is_generating:
            print(f"Pattern generation already in progress, skipping...")
            return False
            
        self.is_generating = True
        try:
            # pattern_datetimeì´ Noneì¸ ê²½ìš° í˜„ì¬ ì‹œê° ì‚¬ìš©
            if pattern_datetime is None:
                pattern_datetime = datetime.now()
                print(f"Using current time for pattern generation: {pattern_datetime.isoformat()}")
            
            # ì˜¤ë˜ëœ ë¡œê·¸íŒŒì¼ ì •ë¦¬ (3ì¼ ì´ìƒ)
            cleanup_old_logs('pattern_log', days=3)
            
            # ë¡œê·¸ íŒŒì¼ ì„¤ì •
            print(f"\nUpdating pattern at {pattern_datetime.isoformat()}")
            log_filename = f'pattern_log/pattern_calculation_{pattern_datetime.isoformat().replace(":", "-")}.log'

            with redirect_stdout(log_filename):
                new_pattern = {
                    "dealer": {},
                    "support": {},
                    "bracelet": {}
                }
                
                # 1. ì•…ì„¸ì„œë¦¬ ì½ê¸° ë° íŒ¨í„´ ë§Œë“¤ê¸°
                start_time = datetime.now()
                print(f"Starting accessory pattern generation...")
                
                dealer_patterns, support_patterns = self._calculate_accessory_prices(pattern_datetime)
                new_pattern["dealer"] = dealer_patterns
                new_pattern["support"] = support_patterns
                
                accessory_duration = (datetime.now() - start_time).total_seconds()
                print(f"Calculating acc patterns duration: {accessory_duration:.1f}s")

                # 2. íŒ”ì°Œ ì½ê¸° ë° íŒ¨í„´ ë§Œë“¤ê¸°
                start_time = datetime.now()
                print(f"Starting bracelet pattern generation...")
                
                bracelet_patterns = self._calculate_bracelet_prices(pattern_datetime)
                new_pattern["bracelet"] = bracelet_patterns

                bracelet_duration = (datetime.now() - start_time).total_seconds()
                print(f"Calculating bracelet patterns duration: {bracelet_duration:.1f}s")
                total_bracelet_patterns = len(bracelet_patterns)
                print(f"Generated {total_bracelet_patterns} total bracelet patterns")

                # 3. pattern DBì— í•œ ë²ˆì— ì“°ê¸°
                start_time = datetime.now()
                print(f"Writing all patterns to database...")
                
                with self.pattern_db.get_write_session() as write_session:
                    # ê¸°ì¡´ í™œì„± íŒ¨í„´ í™•ì¸
                    latest_cycle = write_session.query(AuctionPricePattern)\
                        .order_by(AuctionPricePattern.pattern_datetime.desc())\
                        .first()
                    
                    # í…Œì´ë¸”ì´ ë¹„ì–´ìˆê±°ë‚˜, í˜„ì¬ íŒ¨í„´ì´ ë” ìµœì‹ ì¸ ê²½ìš° True
                    is_latest = latest_cycle is None or latest_cycle.pattern_datetime <= pattern_datetime
                    
                    print(f"Latest pattern datetime: {latest_cycle.pattern_datetime if latest_cycle else 'None'}")
                    print(f"Current pattern datetime: {pattern_datetime.isoformat()}")
                    print(f"Is latest: {is_latest}")

                    # ìƒˆ íŒ¨í„´ ë©”íƒ€ë°ì´í„° ìƒì„±
                    new_pattern_entry = AuctionPricePattern(
                        pattern_datetime=pattern_datetime,
                        is_active=is_latest
                    )

                    if is_latest: # type: ignore
                        # ê¸°ì¡´ í™œì„± íŒ¨í„´ ë¹„í™œì„±í™”
                        write_session.query(AuctionPricePattern).filter_by(is_active=True).update(
                            {"is_active": False}
                        )

                    write_session.add(new_pattern_entry)

                    # ì•…ì„¸ì„œë¦¬ íŒ¨í„´ ì €ì¥
                    for role in ['dealer', 'support']:
                        for cache_key, pattern_data in new_pattern[role].items():
                            grade, part, level, pattern_key = cache_key.split(':', 3)

                            acc_pattern = AccessoryPricePattern(
                                pattern_datetime=pattern_datetime,
                                grade=grade,
                                part=part,
                                level=int(level),
                                pattern_key=pattern_key,
                                role=role,
                                # ê³µí†µ í•„ë“œ
                                model_type=pattern_data['model_type'],
                                base_price=pattern_data['base_price'],
                                total_sample_count=pattern_data['total_sample_count'],
                                r_squared=pattern_data.get('r_squared'),
                                success_rate=pattern_data.get('success_rate'),
                                sold_count=pattern_data.get('sold_count'),
                                expired_count=pattern_data.get('expired_count'),
                                # Multilinear regression ë°ì´í„° (í•„ìš”ì‹œì—ë§Œ)
                                intercept=pattern_data.get('intercept'),
                                coefficients=pattern_data.get('coefficients'),
                                feature_names=pattern_data.get('feature_names')
                            )
                            write_session.add(acc_pattern)

                    # íŒ”ì°Œ íŒ¨í„´ ì €ì¥
                    for cache_key, pattern_data in new_pattern["bracelet"].items():
                        # cache_key ì˜ˆì‹œ: "ê³ ëŒ€:(('ì‹ ì†', 80), ('ì¹˜ëª…', 90)):2"
                        parts = cache_key.split(':', 2)
                        grade = parts[0]
                        sorted_stats = parts[1]  # ëª¨ë“  ìŠ¤íƒ¯ ì •ë³´
                        extra_slots = parts[2]

                        bracelet_pattern = BraceletPricePattern(
                            pattern_datetime=pattern_datetime,
                            grade=grade,
                            sorted_stats=sorted_stats,
                            extra_slots=extra_slots,
                            price=pattern_data['price'],
                            total_sample_count=pattern_data['total_sample_count'],
                            success_rate=pattern_data.get('success_rate'),
                            sold_count=pattern_data.get('sold_count'),
                            expired_count=pattern_data.get('expired_count')
                        )
                        write_session.add(bracelet_pattern)

                write_duration = (datetime.now() - start_time).total_seconds()
                print(f"Writing patterns duration: {write_duration:.1f}s")

            completion_time = datetime.now()
            total_duration = (completion_time - pattern_datetime).total_seconds()
            print(f"Pattern generation completed at {completion_time.isoformat()}")
            print(f"Total pattern generation duration: {total_duration:.1f}s")
            print(f"Pattern collection created for datetime: {pattern_datetime.isoformat()}")
            
            # íŒ¨í„´ ì—…ë°ì´íŠ¸ ì™„ë£Œ ì‹ í˜¸ ë°œì†¡ (ì˜µì…˜)
            if send_signal:
                self._send_pattern_update_signal(pattern_datetime, completion_time)
            
            return True

        except Exception as e:
            print(f"Error updating price patterns: {e}")
            import traceback
            traceback.print_exc()
            return False
        finally:
            self.is_generating = False

    def _calculate_accessory_prices(self, pattern_datetime: datetime) -> tuple[Dict, Dict]:
        """ì•…ì„¸ì„œë¦¬ íŒ¨í„´ë³„ ê°€ê²© ê³„ì‚°"""
        with self.main_db.get_read_session() as read_session:
            # íŒ¨í„´ ìƒì„±ìš©: ACTIVE + 7ì¼ ì´ë‚´ SOLD
            active_accessories = (
                read_session.query(AuctionAccessory)
                .filter(
                    (AuctionAccessory.status == AuctionStatus.ACTIVE)
                    | (
                        (AuctionAccessory.status == AuctionStatus.SOLD)
                        & (
                            AuctionAccessory.sold_at
                            >= pattern_datetime - timedelta(days=7)
                        )
                    )
                )
                .all()
            )
            
            # íŒë§¤ ì„±ê³µë¥  ê³„ì‚°ìš©: ìµœê·¼ 30ì¼ ì´ë‚´ SOLD + EXPIRED
            success_rate_window_days = config.pattern_generator_settings.get("success_rate_window_days", 30)
            historical_accessories = (
                read_session.query(AuctionAccessory)
                .filter(
                    (
                        (AuctionAccessory.status == AuctionStatus.SOLD)
                        & (
                            AuctionAccessory.sold_at
                            >= pattern_datetime - timedelta(days=success_rate_window_days)
                        )
                    )
                    | (
                        (AuctionAccessory.status == AuctionStatus.EXPIRED)
                        & (
                            AuctionAccessory.last_seen_at
                            >= pattern_datetime - timedelta(days=success_rate_window_days)
                        )
                    )
                )
                .all()
            )

            print(f"Found {len(active_accessories)} accessory records for pattern generation")

            # ë”œëŸ¬ìš©/ì„œí¬í„°ìš© ë°ì´í„° ê·¸ë£¹í™” (ê°€ê²© ê³„ì‚°ìš©)
            dealer_groups = {}
            support_groups = {}

            for accessory in active_accessories:
                dealer_key = create_accessory_pattern_key(accessory, "dealer")
                support_key = create_accessory_pattern_key(accessory, "support")

                # ë”œëŸ¬ìš© ê·¸ë£¹ ì¶”ê°€
                if dealer_key not in dealer_groups:
                    dealer_groups[dealer_key] = []
                dealer_groups[dealer_key].append(accessory)

                # ì„œí¬í„°ìš© ê·¸ë£¹ ì¶”ê°€
                if support_key not in support_groups:
                    support_groups[support_key] = []
                support_groups[support_key].append(accessory)

            # íŒë§¤ ì„±ê³µë¥  ê³„ì‚°ìš© ê·¸ë£¹í™”
            dealer_historical_groups = {}
            support_historical_groups = {}

            for accessory in historical_accessories:
                dealer_key = create_accessory_pattern_key(accessory, "dealer")
                support_key = create_accessory_pattern_key(accessory, "support")

                # ë”œëŸ¬ìš© ê·¸ë£¹ ì¶”ê°€
                if dealer_key not in dealer_historical_groups:
                    dealer_historical_groups[dealer_key] = []
                dealer_historical_groups[dealer_key].append(accessory)

                # ì„œí¬í„°ìš© ê·¸ë£¹ ì¶”ê°€
                if support_key not in support_historical_groups:
                    support_historical_groups[support_key] = []
                support_historical_groups[support_key].append(accessory)

            # ê° ê·¸ë£¹ë³„ë¡œ ê°€ê²© ê³„ì‚° (íŒë§¤ ì„±ê³µë¥  í¬í•¨)
            dealer_patterns = {}
            for key, items in dealer_groups.items():
                historical_items = dealer_historical_groups.get(key, [])
                price_data = self._calculate_accessory_group_prices(items, key, "dealer", historical_items)
                if price_data:
                    dealer_patterns[key] = price_data

            support_patterns = {}
            for key, items in support_groups.items():
                historical_items = support_historical_groups.get(key, [])
                price_data = self._calculate_accessory_group_prices(items, key, "support", historical_items)
                if price_data:
                    support_patterns[key] = price_data

        return dealer_patterns, support_patterns

    def _calculate_bracelet_prices(self, pattern_datetime: datetime) -> Dict:
        """íŒ”ì°Œ íŒ¨í„´ë³„ ê°€ê²© ê³„ì‚°"""
        with self.main_db.get_read_session() as session:
            # íŒ¨í„´ ìƒì„±ìš©: ACTIVE + 7ì¼ ì´ë‚´ SOLD
            bracelets = (
                session.query(AuctionBracelet)
                .filter(
                    (AuctionBracelet.status == AuctionStatus.ACTIVE)
                    | (
                        (AuctionBracelet.status == AuctionStatus.SOLD)
                        & (
                            AuctionBracelet.sold_at
                            >= pattern_datetime - timedelta(days=7)
                        )
                    )
                )
                .all()
            )
            
            # íŒë§¤ ì„±ê³µë¥  ê³„ì‚°ìš©: ìµœê·¼ 30ì¼ ì´ë‚´ SOLD + EXPIRED
            success_rate_window_days = config.pattern_generator_settings.get("success_rate_window_days", 30)
            historical_bracelets = (
                session.query(AuctionBracelet)
                .filter(
                    (
                        (AuctionBracelet.status == AuctionStatus.SOLD)
                        & (
                            AuctionBracelet.sold_at
                            >= pattern_datetime - timedelta(days=success_rate_window_days)
                        )
                    )
                    | (
                        (AuctionBracelet.status == AuctionStatus.EXPIRED)
                        & (
                            AuctionBracelet.last_seen_at
                            >= pattern_datetime - timedelta(days=success_rate_window_days)
                        )
                    )
                )
                .all()
            )

            print(f"Found {len(bracelets)} bracelet records for pattern generation")

            # íŒ”ì°Œ ê·¸ë£¹í™” (ê°€ê²© ê³„ì‚°ìš©)
            bracelet_groups = {}
            for bracelet in bracelets:
                cache_key = create_bracelet_pattern_key(bracelet)
                if cache_key not in bracelet_groups:
                    bracelet_groups[cache_key] = []
                bracelet_groups[cache_key].append(bracelet)

            # íŒë§¤ ì„±ê³µë¥  ê³„ì‚°ìš© ê·¸ë£¹í™”
            bracelet_historical_groups = {}
            for bracelet in historical_bracelets:
                cache_key = create_bracelet_pattern_key(bracelet)
                if cache_key not in bracelet_historical_groups:
                    bracelet_historical_groups[cache_key] = []
                bracelet_historical_groups[cache_key].append(bracelet)

            # ê° ê·¸ë£¹ë³„ë¡œ ê°€ê²© ê³„ì‚° (íŒë§¤ ì„±ê³µë¥  í¬í•¨)
            result = {}
            for key, items in bracelet_groups.items():
                historical_items = bracelet_historical_groups.get(key, [])
                price_data = self._calculate_bracelet_group_prices(items, key, historical_items)
                if price_data:
                    result[key] = price_data

            print(f"Generated {len(result)} total bracelet patterns")

        return result

    def _calculate_accessory_group_prices(self, items: List[AuctionAccessory], exclusive_key: str, role: str, historical_items: List[AuctionAccessory] = None) -> Optional[Dict]:
        """ê·¸ë£¹ì˜ ê°€ê²© í†µê³„ ê³„ì‚° - Multilinear Regression ëª¨ë¸"""
        if not items:
            return None
        
        _, part, _, *_ = exclusive_key.split(':')
        
        print(f"\n=== Calculating Multilinear Regression for {exclusive_key} ({role}) ===")
        print(f"Total items in group: {len(items)}")
        
        filtered_items = []
        excluded_option_names = set()

        # exclusive_keyì—ì„œ í˜„ì¬ íŒ¨í„´ì— í¬í•¨ëœ ì˜µì…˜ë“¤ ì¶”ì¶œ
        current_pattern_options = set()
        if ':' in exclusive_key:
            pattern_part = exclusive_key.split(':', 3)[-1]  # "base" ë˜ëŠ” ì˜µì…˜ ë¦¬ìŠ¤íŠ¸
            if pattern_part != "base":
                try:
                    # ì˜ˆ: "[('ì ì£¼í”¼', 1.2), ('ì¶”í”¼', 1.6)]" -> {"ì ì£¼í”¼", "ì¶”í”¼"}
                    import ast
                    option_list = ast.literal_eval(pattern_part)
                    if isinstance(option_list, list):
                        current_pattern_options = {opt_name for opt_name, _ in option_list}
                except:
                    pass  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¹ˆ set ìœ ì§€
        
        # ë‹¤ë¥¸ ì—­í• ì˜ exclusive ì˜µì…˜ë“¤ ì¤‘ í˜„ì¬ íŒ¨í„´ì— í¬í•¨ëœ ê²ƒë“¤ì€ ì œì™¸í•˜ì§€ ì•ŠìŒ
        for group_role in ["dealer", "support"]:
            if group_role != role and part in self.EXCLUSIVE_OPTIONS:
                for exc_opt in self.EXCLUSIVE_OPTIONS[part].get(group_role, []):
                    # í˜„ì¬ íŒ¨í„´ì— í¬í•¨ëœ ì˜µì…˜ì´ ì•„ë‹Œ ê²½ìš°ë§Œ ì œì™¸ ëŒ€ìƒì— ì¶”ê°€
                    if exc_opt not in current_pattern_options:
                        excluded_option_names.add(exc_opt)

        # ì•„ì´í…œë³„ë¡œ ì˜µì…˜ ê²€ì‚¬
        for item in items:
            has_excluded_option = False
            for option in item.raw_options:
                if option.option_name in excluded_option_names:
                    has_excluded_option = True
                    break
            if not has_excluded_option:
                filtered_items.append(item)

        print(f"Items after exclusive option filtering: {len(filtered_items)}")

        # ì—­í• ë³„ ê´€ë ¨ ì˜µì…˜ ê°€ì ¸ì˜¤ê¸° (í”¼ì²˜ ìˆœì„œ ì •ì˜)
        all_feature_names = config.role_related_options[role]
        print(f"Available features for {role}: {all_feature_names}")

        # í”¼ì²˜ ë²¡í„°ì™€ íƒ€ê²Ÿ ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
        X_all = []  # ì „ì²´ í”¼ì²˜ ë§¤íŠ¸ë¦­ìŠ¤
        y = []  # íƒ€ê²Ÿ ê°€ê²© ë²¡í„°
        
        for item in filtered_items:
            if item.price and item.status in [AuctionStatus.ACTIVE, AuctionStatus.SOLD]:
                # í”¼ì²˜ ë²¡í„° ì¶”ì¶œ
                features = extract_common_option_features(item, role)
                
                # feature_names ìˆœì„œëŒ€ë¡œ í”¼ì²˜ ë²¡í„° ìƒì„±
                feature_vector = []
                for feature_name in all_feature_names:
                    feature_vector.append(features.get(feature_name, 0.0))
                
                X_all.append(feature_vector)
                y.append(float(item.price))
        
        min_samples = config.pattern_generator_settings["min_regression_samples"]
        if len(X_all) < min_samples:
            print(f"Multilinear regression: ë°ì´í„° ë¶€ì¡± ({len(X_all)}ê°œ)")
            return None
        
        X_all_array = np.array(X_all)
        y_array = np.array(y)
        
        # ê° í”¼ì²˜ë³„ë¡œ ê°œë³„ ìƒê´€ê´€ê³„ ë¶„ì„
        print(f"Analyzing individual feature correlations:")
        valid_features = []
        valid_feature_indices = []
        min_correlation = config.pattern_generator_settings.get("min_feature_correlation", 0.1)
        
        for i, feature_name in enumerate(all_feature_names):
            # í•´ë‹¹ í”¼ì²˜ê°€ 0ì´ ì•„ë‹Œ ìƒ˜í”Œë“¤ë¡œ ìƒê´€ê´€ê³„ ê³„ì‚°
            feature_values = X_all_array[:, i]
            non_zero_mask = feature_values > 0
            
            if np.sum(non_zero_mask) < 5:  # ìµœì†Œ 5ê°œ ìƒ˜í”Œ í•„ìš”
                print(f"  {feature_name}: Skip (insufficient non-zero samples: {np.sum(non_zero_mask)})")
                continue
            
            # í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ê³„ì‚° (ë¶„ì‚° ì²´í¬ í¬í•¨)
            feature_subset = feature_values[non_zero_mask]
            price_subset = y_array[non_zero_mask]
            
            # ë¶„ì‚°ì´ 0ì¸ì§€ ì²´í¬ (ëª¨ë“  ê°’ì´ ë™ì¼í•œ ê²½ìš°)
            if np.var(feature_subset) == 0 or np.var(price_subset) == 0:
                print(f"  {feature_name}: Skip (zero variance)")
                continue
            
            correlation = np.corrcoef(feature_subset, price_subset)[0, 1]
            
            if np.isnan(correlation):
                print(f"  {feature_name}: Skip (correlation is NaN)")
                continue
            
            abs_correlation = abs(correlation)
            if abs_correlation >= min_correlation:
                valid_features.append(feature_name)
                valid_feature_indices.append(i)
                print(f"  {feature_name}: Include (correlation: {correlation:.3f})")
            else:
                print(f"  {feature_name}: Skip (low correlation: {correlation:.3f})")
        
        if not valid_features:
            print(f"No valid features found - using minimum price model")
            min_price = int(np.min(y_array))
            return {
                'model_type': 'minimum_price',
                'base_price': min_price,
                'total_sample_count': len(filtered_items),
                'r_squared': 0.0,
                'intercept': None,
                'coefficients': None,
                'feature_names': None
            }
        
        # ìœ íš¨í•œ í”¼ì²˜ë§Œìœ¼ë¡œ ìƒˆë¡œìš´ ë§¤íŠ¸ë¦­ìŠ¤ êµ¬ì„±
        X = X_all_array[:, valid_feature_indices]
        feature_names = valid_features
        
        print(f"Selected features: {feature_names}")
        print(f"Final feature matrix shape: {X.shape}")
        print(f"Target vector shape: {y_array.shape}")
        
        # ìƒìˆ˜í•­ì„ ìœ„í•œ 1ì˜ ì—´ ì¶”ê°€
        X_with_intercept = np.column_stack([np.ones(X.shape[0]), X])
        
        # Non-negative Least Squares (NNLS) ì‚¬ìš©
        try:
            # NNLS: ëª¨ë“  ê³„ìˆ˜ê°€ 0 ì´ìƒì´ ë˜ë„ë¡ ì œì•½í•˜ë©´ì„œ ìµœì†ŒììŠ¹ë²• ìˆ˜í–‰
            coefficients_nnls, residual = nnls(X_with_intercept, y_array)
            
            intercept = float(coefficients_nnls[0])
            coefficients = coefficients_nnls[1:].tolist()
            
            # ê³„ìˆ˜ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            coeff_dict = {}
            for i, feature_name in enumerate(feature_names):
                coeff_dict[feature_name] = float(coefficients[i])
            
            print(f"Non-negative Least Squares (NNLS) results:")
            print(f"  Intercept: {intercept:.2f}")
            for feature_name, coeff in coeff_dict.items():
                print(f"  {feature_name}: {coeff:.2f}")
            print(f"  Samples: {len(X)}")
            
            # ëª¨ë¸ ì„±ëŠ¥ í‰ê°€
            y_pred = X_with_intercept @ coefficients_nnls
            ss_tot = np.sum((y_array - np.mean(y_array)) ** 2)
            ss_res = np.sum((y_array - y_pred) ** 2)
            r_squared = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0
            
            # ì¶”ê°€ ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
            mae = np.mean(np.abs(y_array - y_pred))  # í‰ê·  ì ˆëŒ€ ì˜¤ì°¨
            mape = np.mean(np.abs((y_array - y_pred) / y_array)) * 100  # í‰ê·  ì ˆëŒ€ ë°±ë¶„ìœ¨ ì˜¤ì°¨
            rmse = np.sqrt(np.mean((y_array - y_pred) ** 2))  # RMSE
            
            # ê°€ê²© ë²”ìœ„ ì •ë³´
            price_min, price_max = int(np.min(y_array)), int(np.max(y_array))
            price_mean = int(np.mean(y_array))
            
            print(f"  R-squared: {r_squared:.4f}")
            print(f"  MAPE (í‰ê·  ì˜¤ì°¨ìœ¨): {mape:.1f}%")
            print(f"  MAE (í‰ê·  ì˜¤ì°¨): {mae:,.0f} gold")
            print(f"  Price range: {price_min:,} ~ {price_max:,} gold (í‰ê· : {price_mean:,})")
            
            # ëª¨ë¸ í’ˆì§ˆ íŒì •
            if mape <= 15:
                quality = "Excellent"
            elif mape <= 25:
                quality = "Good"
            elif mape <= 35:
                quality = "Fair"
            else:
                quality = "Poor"
            print(f"  Model Quality: {quality} (MAPE ê¸°ì¤€)")
            
            # íŒë§¤ ì„±ê³µë¥  ê³„ì‚°
            success_rate_result = self._calculate_success_rate(historical_items or [])
            if success_rate_result is not None:
                success_rate, sold_count, expired_count = success_rate_result
                print(f"  Success Rate: {success_rate:.1f}% (SOLD: {sold_count}, EXPIRED: {expired_count})")
            
            # R-squared ê¸°ë°˜ ëª¨ë¸ ì„ íƒ
            min_r_squared = config.pattern_generator_settings.get("min_r_squared_threshold", 0.5)
            
            if r_squared < min_r_squared:
                # R-squaredê°€ ë‚®ìœ¼ë©´ ë‹¨ìˆœ ìµœì €ê°€ ëª¨ë¸ ì‚¬ìš©
                min_price = int(np.min(y_array))
                print(f"  âš ï¸  Low R-squared ({r_squared:.3f}) - using minimum price model: {min_price:,} gold")
                
                result = {
                    'model_type': 'minimum_price',
                    'base_price': min_price,
                    'total_sample_count': len(items),
                    'r_squared': r_squared,
                    # multilinear í•„ë“œë“¤ì€ Noneìœ¼ë¡œ ì„¤ì •
                    'intercept': None,
                    'coefficients': None,
                    'feature_names': None
                }
                
                # íŒë§¤ ì„±ê³µë¥  ë° ê°œìˆ˜ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
                if success_rate_result is not None:
                    success_rate, sold_count, expired_count = success_rate_result
                    result['success_rate'] = success_rate
                    result['sold_count'] = sold_count
                    result['expired_count'] = expired_count
                
                return result
            else:
                # R-squaredê°€ ì¶©ë¶„í•˜ë©´ multilinear regression ëª¨ë¸ ì‚¬ìš©
                print(f"  âœ… Good R-squared ({r_squared:.3f}) - using multilinear model")
                
                result = {
                    'model_type': 'multilinear',
                    'intercept': intercept,
                    'coefficients': coeff_dict,
                    'feature_names': feature_names,
                    'total_sample_count': len(items),
                    'r_squared': r_squared,
                    # ìµœì €ê°€ ì •ë³´ë„ ê°™ì´ ì €ì¥
                    'base_price': int(np.min(y_array))
                }
                
                # íŒë§¤ ì„±ê³µë¥  ë° ê°œìˆ˜ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
                if success_rate_result is not None:
                    success_rate, sold_count, expired_count = success_rate_result
                    result['success_rate'] = success_rate
                    result['sold_count'] = sold_count
                    result['expired_count'] = expired_count
                
                return result
            
        except Exception as e:
            print(f"Non-negative Least Squares failed: {e}")
            import traceback
            traceback.print_exc()
            return None

    def _calculate_bracelet_group_prices(self, items: List[AuctionBracelet], cache_key: str, historical_items: List[AuctionBracelet] = None) -> Optional[Dict]:
        """íŒ”ì°Œ ê·¸ë£¹ì˜ ê°€ê²© í†µê³„ ê³„ì‚°"""
        if not items:
            return None
        
        print(f"\n=== Calculating Bracelet Group Prices for {cache_key} ===")
        print(f"Total items in group: {len(items)}")
        
        # ê°€ê²© í•„í„°ë§ (0ë³´ë‹¤ í° ê°€ê²©ë§Œ)
        valid_items = [item for item in items if item.price is not None and item.price > 0]
        
        if not valid_items:
            print("No valid items with price > 0")
            return None
        
        # ê°€ê²© ì •ë ¬ ë° ê³„ì‚°
        prices = sorted([int(item.price) for item in valid_items])
        reasonable_price = calculate_reasonable_price(prices)
        
        # íŒë§¤ ì„±ê³µë¥  ê³„ì‚°
        success_rate_result = self._calculate_bracelet_success_rate(historical_items or [])
        if success_rate_result is not None:
            success_rate, sold_count, expired_count = success_rate_result
            print(f"  Success Rate: {success_rate:.1f}% (SOLD: {sold_count}, EXPIRED: {expired_count})")
        
        if reasonable_price and reasonable_price > 0:
            result = {
                'price': reasonable_price,
                'total_sample_count': len(valid_items)
            }
            
            # íŒë§¤ ì„±ê³µë¥  ë° ê°œìˆ˜ ì¶”ê°€ (ìˆëŠ” ê²½ìš°ë§Œ)
            if success_rate_result is not None:
                success_rate, sold_count, expired_count = success_rate_result
                result['success_rate'] = success_rate
                result['sold_count'] = sold_count
                result['expired_count'] = expired_count
                
            return result
        
        return None

    def _send_pattern_update_signal(self, pattern_datetime: datetime, completion_time: datetime = None):
        """íŒ¨í„´ ì—…ë°ì´íŠ¸ ì™„ë£Œ ì‹ í˜¸ë¥¼ item_evaluatorì— ë°œì†¡"""
        try:
            from src.common.ipc_utils import notify_pattern_update
            result = notify_pattern_update(pattern_datetime)
            
            if completion_time:
                time_display = completion_time.isoformat()
            else:
                time_display = pattern_datetime.isoformat()
            
            if result:
                print(f"ğŸ“¡ Pattern update signal sent via IPC at {time_display}")
            else:
                print(f"ğŸ“¡ Pattern update signal sent (no active listeners) at {time_display}")
        except Exception as e:
            print(f"Warning: Failed to send pattern update signal: {e}")

    def _calculate_success_rate(self, historical_items: List[AuctionAccessory]) -> Optional[tuple[float, int, int]]:
        """ì•…ì„¸ì„œë¦¬ íŒë§¤ ì„±ê³µë¥  ê³„ì‚°: SOLD / (SOLD + EXPIRED)
        
        Returns:
            tuple[float, int, int] | None: (success_rate, sold_count, expired_count) ë˜ëŠ” None
        """
        if not historical_items:
            return None
        
        sold_count = sum(1 for item in historical_items if item.status == AuctionStatus.SOLD)
        expired_count = sum(1 for item in historical_items if item.status == AuctionStatus.EXPIRED)
        total_count = sold_count + expired_count
        
        if total_count == 0:
            return None
        
        success_rate = (sold_count / total_count) * 100
        return success_rate, sold_count, expired_count

    def _calculate_bracelet_success_rate(self, historical_items: List[AuctionBracelet]) -> Optional[tuple[float, int, int]]:
        """íŒ”ì°Œ íŒë§¤ ì„±ê³µë¥  ê³„ì‚°: SOLD / (SOLD + EXPIRED)
        
        Returns:
            tuple[float, int, int] | None: (success_rate, sold_count, expired_count) ë˜ëŠ” None
        """
        if not historical_items:
            return None
        
        sold_count = sum(1 for item in historical_items if item.status == AuctionStatus.SOLD)
        expired_count = sum(1 for item in historical_items if item.status == AuctionStatus.EXPIRED)
        total_count = sold_count + expired_count
        
        if total_count == 0:
            return None
        
        success_rate = (sold_count / total_count) * 100
        return success_rate, sold_count, expired_count

    def _round_combat_stat(self, grade: str, value: float) -> int:
        """ì „íˆ¬ íŠ¹ì„± ê°’ì„ ê¸°ì¤€ê°’ìœ¼ë¡œ ë‚´ë¦¼"""
        thresholds = config.bracelet_settings["combat_stat_thresholds"]
        combat_stat_bonus = config.bracelet_settings["ancient_combat_stat_bonus"] if grade == "ê³ ëŒ€" else 0
        adjusted_thresholds = [t + combat_stat_bonus for t in thresholds]

        # ê°€ì¥ ê°€ê¹Œìš´ í•˜ìœ„ threshold ë°˜í™˜
        for threshold in adjusted_thresholds:
            if value < threshold:
                return adjusted_thresholds[max(0, adjusted_thresholds.index(threshold) - 1)]
        return adjusted_thresholds[-1]

    def _round_base_stat(self, grade: str, value: float) -> int:
        """ê¸°ë³¸ìŠ¤íƒ¯ ê°’ì„ ê¸°ì¤€ê°’ìœ¼ë¡œ ë‚´ë¦¼"""
        thresholds = config.bracelet_settings["base_stat_thresholds"]
        base_stat_bonus = config.bracelet_settings["ancient_base_stat_bonus"] if grade == "ê³ ëŒ€" else 0
        adjusted_thresholds = [t + base_stat_bonus for t in thresholds]

        # ê°€ì¥ ê°€ê¹Œìš´ í•˜ìœ„ threshold ë°˜í™˜
        for threshold in adjusted_thresholds:
            if value < threshold:
                return adjusted_thresholds[max(0, adjusted_thresholds.index(threshold) - 1)]
        return adjusted_thresholds[-1]
    
    def _get_next_15min_schedule(self) -> datetime:
        """ë‹¤ìŒ 15ë¶„ ê°„ê²© ìŠ¤ì¼€ì¤„ ì‹œê°„ ê³„ì‚° (ì •ê° ê¸°ì¤€)"""
        now = datetime.now()
        # í˜„ì¬ ì‹œê°„ì—ì„œ ë¶„ì„ 15ë¶„ ë‹¨ìœ„ë¡œ ì˜¬ë¦¼
        minutes = now.minute
        next_15min = ((minutes // 15) + 1) * 15
        
        if next_15min >= 60:
            # ë‹¤ìŒ ì‹œê°„
            next_time = now.replace(minute=0, second=0, microsecond=0) + timedelta(hours=1)
        else:
            # ê°™ì€ ì‹œê°„
            next_time = now.replace(minute=next_15min, second=0, microsecond=0)
        
        return next_time
    
    def _copy_latest_pattern(self, new_pattern_datetime: datetime) -> bool:
        """ê°€ì¥ ìµœê·¼ íŒ¨í„´ì„ ë³µì‚¬í•´ì„œ ìƒˆ ì‹œê°„ìœ¼ë¡œ ì €ì¥"""
        try:
            with self.pattern_db.get_write_session() as session:
                # ê°€ì¥ ìµœê·¼ í™œì„± íŒ¨í„´ ì°¾ê¸°
                latest_pattern = session.query(AuctionPricePattern).filter_by(
                    is_active=True
                ).order_by(AuctionPricePattern.pattern_datetime.desc()).first()
                
                if not latest_pattern:
                    print("No existing pattern to copy")
                    return False
                
                print(f"Copying latest pattern from {latest_pattern.pattern_datetime} to {new_pattern_datetime}")
                
                # ê¸°ì¡´ í™œì„± íŒ¨í„´ë“¤ì„ ë¹„í™œì„±í™”
                session.query(AuctionPricePattern).filter_by(is_active=True).update({'is_active': False})
                
                # ìƒˆ ë©”ì¸ íŒ¨í„´ ìƒì„±
                new_pattern = AuctionPricePattern(
                    pattern_datetime=new_pattern_datetime,
                    is_active=True
                )
                session.add(new_pattern)
                session.flush()
                
                # ì•…ì„¸ì„œë¦¬ íŒ¨í„´ë“¤ ë³µì‚¬
                accessory_patterns = session.query(AccessoryPricePattern).filter_by(
                    pattern_datetime=latest_pattern.pattern_datetime
                ).all()
                
                for old_pattern in accessory_patterns:
                    new_accessory_pattern = AccessoryPricePattern(
                        pattern_datetime=new_pattern_datetime,
                        grade=old_pattern.grade,
                        part=old_pattern.part,
                        level=old_pattern.level,
                        pattern_key=old_pattern.pattern_key,
                        role=old_pattern.role,
                        model_type=old_pattern.model_type,
                        base_price=old_pattern.base_price,
                        total_sample_count=old_pattern.total_sample_count,
                        r_squared=old_pattern.r_squared,
                        success_rate=old_pattern.success_rate,
                        sold_count=old_pattern.sold_count,
                        expired_count=old_pattern.expired_count,
                        intercept=old_pattern.intercept,
                        coefficients=old_pattern.coefficients,
                        feature_names=old_pattern.feature_names
                    )
                    session.add(new_accessory_pattern)
                
                # íŒ”ì°Œ íŒ¨í„´ë“¤ ë³µì‚¬
                bracelet_patterns = session.query(BraceletPricePattern).filter_by(
                    pattern_datetime=latest_pattern.pattern_datetime
                ).all()
                
                for old_pattern in bracelet_patterns:
                    new_bracelet_pattern = BraceletPricePattern(
                        pattern_datetime=new_pattern_datetime,
                        grade=old_pattern.grade,
                        sorted_stats=old_pattern.sorted_stats,
                        extra_slots=old_pattern.extra_slots,
                        price=old_pattern.price,
                        total_sample_count=old_pattern.total_sample_count,
                        success_rate=old_pattern.success_rate,
                        sold_count=old_pattern.sold_count,
                        expired_count=old_pattern.expired_count
                    )
                    session.add(new_bracelet_pattern)
                
                session.commit()
                print(f"Pattern copied successfully: {len(accessory_patterns)} accessory + {len(bracelet_patterns)} bracelet patterns")
                return True
                
        except Exception as e:
            print(f"Error copying latest pattern: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _scheduled_pattern_update(self):
        """15ë¶„ ê°„ê²© ìŠ¤ì¼€ì¤„ì— ë”°ë¥¸ íŒ¨í„´ ì—…ë°ì´íŠ¸"""
        try:
            update_time = datetime.now()
            
            if self.collection_signal_received and self.last_collection_time:
                print(f"[{update_time.strftime('%H:%M')}] Collection signal detected, running full pattern generation...")
                
                # ì‹¤ì œ íŒ¨í„´ ìƒì„±
                success = self.update_pattern(send_signal=True)
                
                if success:
                    print(f"Pattern generation completed successfully")
                else:
                    print(f"Pattern generation failed")
                
                # í”Œë˜ê·¸ ë¦¬ì…‹
                self.collection_signal_received = False
                self.last_collection_time = None
                
            else:
                print(f"[{update_time.strftime('%H:%M')}] No collection signal, copying latest pattern...")
                
                # ìµœê·¼ íŒ¨í„´ ë³µì‚¬
                success = self._copy_latest_pattern(update_time)
                
                if success:
                    # íŒ¨í„´ ì—…ë°ì´íŠ¸ ì‹ í˜¸ ë°œì†¡
                    self._send_pattern_update_signal(update_time, update_time)
                    print(f"Latest pattern copied successfully")
                else:
                    print(f"Failed to copy latest pattern")
                    
        except Exception as e:
            print(f"Error in scheduled pattern update: {e}")
            import traceback
            traceback.print_exc()
    
    def run_service(self):
        """IPC ì„œë¹„ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰ (ë¬´í•œ ëŒ€ê¸°)"""
        import time
        import signal
        from src.common.ipc_utils import IPCServer, MessageTypes
        
        print("Starting Pattern Generator Service...")
        
        # IPC ì„œë²„ ì„¤ì •
        ipc_server = IPCServer(service_name="pattern_generator")
        
        def handle_collection_completed(message):
            """ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ì‹ í˜¸ ì²˜ë¦¬ - 15ë¶„ ìŠ¤ì¼€ì¤„ë§ ë°©ì‹"""
            try:
                completion_time_str = message['data']['completion_datetime']
                completion_time = datetime.fromisoformat(completion_time_str)
                
                print(f"Received collection completion signal: {completion_time.isoformat()}")
                print("Signal queued for next scheduled update (every 15 minutes)")
                
                # í”Œë˜ê·¸ ì„¤ì • (ì¦‰ì‹œ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)
                self.collection_signal_received = True
                self.last_collection_time = completion_time
                
                # ë‹¤ìŒ ìŠ¤ì¼€ì¤„ ì‹œê°„ ì¶œë ¥
                next_schedule = self._get_next_15min_schedule()
                print(f"Next scheduled update: {next_schedule.strftime('%H:%M')}")
                
                return {
                    'status': 'queued', 
                    'message': 'Collection signal queued for next scheduled update',
                    'next_schedule': next_schedule.isoformat()
                }
                    
            except Exception as e:
                print(f"Error handling collection completion: {e}")
                import traceback
                traceback.print_exc()
                return {'status': 'error', 'message': str(e)}
        
        def handle_health_check(message):
            """í—¬ìŠ¤ì²´í¬ ì²˜ë¦¬"""
            return {
                'status': 'healthy',
                'service': 'pattern_generator',
                'timestamp': datetime.now().isoformat()
            }
        
        # í•¸ë“¤ëŸ¬ ë“±ë¡
        ipc_server.register_handler(MessageTypes.COLLECTION_COMPLETED, handle_collection_completed)
        ipc_server.register_handler(MessageTypes.HEALTH_CHECK, handle_health_check)
        
        # ì¢…ë£Œ ì‹ í˜¸ í•¸ë“¤ëŸ¬
        is_running = [True]  # ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ì„œ nonlocal ë¬¸ì œ í•´ê²°
        
        def signal_handler(signum, frame):
            print(f"\nReceived signal {signum}")
            is_running[0] = False
        
        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)
        
        # IPC ì„œë²„ ì‹œì‘
        try:
            ipc_server.start_server()
            print("IPC server started")
            print("Pattern Generator Service is ready!")
            print("15-minute scheduled pattern updates enabled")
            
            # ë‹¤ìŒ ìŠ¤ì¼€ì¤„ ì‹œê°„ ê³„ì‚°
            next_schedule_time = self._get_next_15min_schedule()
            print(f"Next scheduled update: {next_schedule_time.strftime('%H:%M')}")
            
            # ë©”ì¸ ë£¨í”„ - 15ë¶„ ê°„ê²© ìŠ¤ì¼€ì¤„ë§
            while is_running[0]:
                current_time = datetime.now()
                
                # ìŠ¤ì¼€ì¤„ ì‹œê°„ì´ ë˜ì—ˆëŠ”ì§€ ì²´í¬ (1ë¶„ ì—¬ìœ )
                if current_time >= next_schedule_time:
                    print(f"\n=== Scheduled Update Trigger ({current_time.strftime('%H:%M')}) ===")
                    
                    # ìŠ¤ì¼€ì¤„ëœ íŒ¨í„´ ì—…ë°ì´íŠ¸ ì‹¤í–‰
                    self._scheduled_pattern_update()
                    
                    # ë‹¤ìŒ ìŠ¤ì¼€ì¤„ ì‹œê°„ ê³„ì‚°
                    next_schedule_time = self._get_next_15min_schedule()
                    print(f"Next scheduled update: {next_schedule_time.strftime('%H:%M')}")
                    print("=== Waiting for signals ===\n")
                
                time.sleep(30)  # 30ì´ˆë§ˆë‹¤ ì²´í¬
                
        except KeyboardInterrupt:
            print("\nReceived interrupt signal")
        finally:
            print("Stopping Pattern Generator Service...")
            ipc_server.stop_server()
            print("Service stopped")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ë¡œìŠ¤íŠ¸ì•„í¬ íŒ¨í„´ ìƒì„±ê¸°')
    parser.add_argument('--datetime', type=str, 
                       help='íŒ¨í„´ ìƒì„± ê¸°ì¤€ ì‹œê° (ISO format, ê¸°ë³¸ê°’: í˜„ì¬ ì‹œê°)')
    parser.add_argument('--service', action='store_true',
                       help='IPC ì„œë¹„ìŠ¤ ëª¨ë“œë¡œ ì‹¤í–‰ (ë¬´í•œ ëŒ€ê¸°)')
    args = parser.parse_args()
    
    # DB ë§¤ë‹ˆì € ì´ˆê¸°í™”
    from src.database.raw_database import RawDatabaseManager
    db_manager = RawDatabaseManager()
    generator = PatternGenerator(db_manager)
    
    if args.service:
        # ì„œë¹„ìŠ¤ ëª¨ë“œ
        print("=== Pattern Generator Service Mode ===")
        generator.run_service()
    else:
        # ì¼íšŒì„± ì‹¤í–‰ ëª¨ë“œ
        print("=== Pattern Generation Only Mode ===")
        start_time = datetime.now()
        
        # ê¸°ì¤€ ì‹œê° ì„¤ì •
        if args.datetime:
            try:
                pattern_datetime = datetime.fromisoformat(args.datetime)
                print(f"Using specified datetime: {pattern_datetime.isoformat()}")
            except ValueError:
                print(f"Invalid datetime format: {args.datetime}")
                print("Using current time instead")
                pattern_datetime = None
        else:
            pattern_datetime = None
        
        # íŒ¨í„´ ìƒì„± ì‹¤í–‰
        success = generator.update_pattern(pattern_datetime)
        
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        if success:
            print(f"Pattern generation completed! Duration: {duration}s")
        else:
            print(f"Pattern generation failed! Duration: {duration}s")


if __name__ == "__main__":
    main()